{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Natural Language Processing\n",
    "\n",
    "Write your name below [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name:          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The code cells below extract the plain text Wikipedia entry for *Eastern Connecticut State University*. The details for this step is beyond the scope of our class, but if you are curious I can explain more about what this code does. To complete the assignment, you just need to understand the text of the Wikipedia article is stored in the variable *text*, which you will first analyze using *TextBlob*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# download the wikipedia entry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/w/api.php?action=query&format=json&titles=Eastern_Connecticut_State_University&prop=extracts&explaintext')\n",
    "\n",
    "if page.status_code != 200 :\n",
    "    print('Error: Page Not Found. Try again or ask Dr. Dancik for help')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# result is in json format, which we convert to a dictionary using json.loads\n",
    "import json\n",
    "j = json.loads(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# extract the text\n",
    "\n",
    "# first find the pageId\n",
    "pageId = list(j['query']['pages'].keys())[0]\n",
    "pageId\n",
    "\n",
    "# get the extract for this pageId, and store the text in the variable 'text'\n",
    "text = j['query']['pages'][pageId]['extract']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## *TextBlob* questions\n",
    "\n",
    "The code below imports *TextBlob* and creates a *blob* from the Wikipedia text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1  <span style = 'font-size: 80%'>(5 points each = 15 points)</span>\n",
    "(a) How many words are in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) How many sentences are in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(c) What is the 3rd sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2 <span style = 'font-size: 80%'>(5 points each = 10 points)</span>\n",
    "(a) Print out all the sentences that contain 'Eastern Connecticut State University'. Print a blank line after each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) A programmer may want to repeat this kind of analysis for multiple words or phrases. This is where a *function* can be very useful.\n",
    "Write a function that has the following format:\n",
    "\n",
    "```python\n",
    "def printSentences(blob, search) :\n",
    "    # prints out all sentences in the 'blob' that contain the 'search' term.\n",
    "```\n",
    "\n",
    "Then use this function to print out all sentences that contain 'Willimantic'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 <span style = 'font-size: 80%'>(5 points each = 10 points)</span>\n",
    "Recall that the word counts are stored in the *blob.word_counts* dictionary. \n",
    "\n",
    "(a) How many times does the word 'eastern' appear in the text? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) How many times does the word 'student' appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4 <span style = 'font-size: 80%'>(7 points each = 21 points)</span>\n",
    "(a) Use list comprehension to create a list of word-frequency pairs for each word. Then sort this list from the most frequent word to the least frequent word. The cell below imports the *itemgetter* function which is useful for sorting lists when each item in the list is a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) It is very common to convert a word count dictionary to a sorted list of word-frequency pairs (tuples) when doing natural language processing. Write a function called *getWordCounts* that takes a *blob* as an input and returns a list of word-frequency pairs, where the words are sorted from the most frequent to the least frequent. Then use this function to get a list of word counts as was done for (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(c) Your results above should show that 'the' is the most common word. Let's now remove common words like 'the' and 'and'. The code below creates a set of stopwords that are stored in *sw*. Create a new list of word-frequency pairs but with the stopwords removed. Display the word counts, either as a list of tuples or as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5 <span style = 'font-size: 80%'>(7 points)</span>\n",
    "\n",
    "Generate a word cloud directly from the text, but convert all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6 <span style = 'font-size: 80%'>(5 points)</span>\n",
    "\n",
    "Use TextBlob's *translate* function to translate the first sentence of the Wikipedia entry into Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Spacy questions\n",
    "\n",
    "Run the code below to load the *en_core_web_sm* language model and carries out natural language processing using spacy, storing the results in *doc*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 7 <span style = 'font-size: 80%'>(5 points each = 10 points)</span>\n",
    "\n",
    "Recall that *doc* is a sequence of tokens (words). \n",
    "\n",
    "(a) Use slicing to view the first 20 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) Use slicing to view the last 20 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 8 <span style = 'font-size: 80%'>(5 points)</span>\n",
    "\n",
    "Use displacy to view the text where the named entities are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 9 <span style = 'font-size: 80%'>(7 points)</span>\n",
    "\n",
    "Iterate through each token and output all of the dates. Note that if a token is a date then its entity label *ent.label_* will be equal to 'DATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In *Spacy*, the sentences from text are stored in *doc.sents*, and we can iterate through each sentence by using \n",
    "\n",
    "```python\n",
    "for sentence in doc.sents :\n",
    "    # do something for each sentence\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The code below creates a function named *containsDate* that returns *True* if a sentence *x* contains a date; otherwise the function returns *False*. The code demonstrates this function by testing it on the first and second sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# check all named entities in 'x' and return True if at least one is 'DATE'\n",
    "def containsDate(x) :\n",
    "    for ent in x.ents:\n",
    "        if ent.label_ == 'DATE' :\n",
    "            return True\n",
    "    return False   \n",
    "\n",
    "\n",
    "# get a list of sentences\n",
    "sentences = list(doc.sents)\n",
    "\n",
    "# look at first sentence, which does not contain a date\n",
    "s = sentences[0]\n",
    "print (s)\n",
    "print('contains date:', containsDate(s))\n",
    "print()\n",
    "\n",
    "        \n",
    "# look at second sentence, which does contain a date\n",
    "s = sentences[1]\n",
    "print (s)\n",
    "print('contains date:', containsDate(s))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 10 <span style = 'font-size: 80%'>(7 points)</span>\n",
    "\n",
    "Use the *containsDate* function above to output all the sentences that contain a date. Print a blank line after each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
