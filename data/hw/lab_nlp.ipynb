{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Natural Language Processing\n",
    "\n",
    "Write your name in the Markdown cell below [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name:          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Lab setup\n",
    "\n",
    "The code cells below extract the plain text Wikipedia entry for *Eastern Connecticut State University*. The details for this code are beyond the scope of our class, but if you are curious I can explain more about what this code does. To complete the assignment, you just need to understand that the text of the Wikipedia article is stored in the variable *text*, which you will first analyze using *TextBlob*. The assignment begins with the *Textblob questions* section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# download the wikipedia entry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/w/api.php?action=query&format=json&titles=Eastern_Connecticut_State_University&prop=extracts&explaintext')\n",
    "\n",
    "if page.status_code != 200 :\n",
    "    print('Error: Page Not Found. Try again or ask Dr. Dancik for help')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# result is in json format, which we convert to a dictionary using json.loads\n",
    "import json\n",
    "j = json.loads(page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# extract the text\n",
    "\n",
    "# first find the pageId\n",
    "pageId = list(j['query']['pages'].keys())[0]\n",
    "pageId\n",
    "\n",
    "# get the extract for this pageId, and store the text in the variable 'text'\n",
    "text = j['query']['pages'][pageId]['extract']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## *TextBlob* questions\n",
    "\n",
    "The code below imports *TextBlob* and creates a *blob* from the Wikipedia text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1  <span style = 'font-size: 80%'>[10 points]</span>\n",
    "(a) How many words are in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) How many sentences are in the text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(c) Display the 3rd sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "(a) Print out all the sentences that contain 'Eastern'. Print a blank line after each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) A programmer may want to repeat this kind of analysis for multiple words or phrases. This is where a *function* can be very useful.\n",
    "Write a function that has the following format:\n",
    "\n",
    "```python\n",
    "def printSentences(blob, search) :\n",
    "    # prints out all sentences in the 'blob' that contain the 'search' term.\n",
    "```\n",
    "\n",
    "Then use this function to print out all sentences that contain 'Willimantic'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 3 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "Recall that the word counts are stored in the *blob.word_counts* dictionary. \n",
    "\n",
    "(a) How many times does the word 'eastern' appear in the text? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) How many times does the word 'student' appear? For this question, display the answer in the following format: \n",
    "\n",
    "```\n",
    "The word 'student' appears 7 times\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "\n",
    "Output all of the noun phrases that contain the word 'university'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "The code below uses list comprehension to create a list of word-frequency pairs for each word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "wc = [(word,count) for word,count in blob.word_counts.items()]\n",
    "wc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(a) Sort this list from the most frequent word to the least frequent word, and display the first 5 words in sorted order. (You can display the first 5 tuples, as above) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) Your results above should show that 'the' is the most common word. Let's now remove common words like 'the' and 'and'. The code below creates a set of stopwords that are stored in *sw*. Create a new list of word-frequency pairs but with the stopwords removed. Display the word counts, either as a list of tuples or as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "\n",
    "Generate a word cloud directly from the text, but convert all text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "\n",
    "\n",
    "<h3 style = 'color:red'> Skip this question -- textblob no longer supports translation </h3>\n",
    "\n",
    "Use TextBlob's *translate* function to translate \n",
    "\n",
    "(a) the first sentence of the Wikipedia entry into Spanish \n",
    "\n",
    "(b) the second sentence of the Wikipedia entry into German\n",
    "\n",
    "(Note: the language codes for Google Translate are available here: https://cloud.google.com/translate/docs/languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Spacy questions\n",
    "\n",
    "Run the code below to load the *en_core_web_sm* language model and carry out natural language processing using spacy, storing the results in *doc*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 8 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "\n",
    "Recall that *doc* is a sequence of tokens (these include words and punctuation). \n",
    "\n",
    "(a) Use slicing to view the first 20 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) Use slicing to view the last 20 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 9 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "\n",
    "Use displacy to view the text where the named entities are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 10 <span style = 'font-size: 80%'>[10 points]</span>\n",
    "\n",
    "(a) Iterate through each token and output all of the dates. Note that if a token is a date then its entity label *ent.label_* will be equal to 'DATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "(b) In *spacy*, the sentences are stored in *doc.sents*. For a sentence *s*, we can also get its named entities by using *s.ent*. The code below uses *nested* for loops to iterate through each named entity of each sentence, and prints out the sentence if it contains a date. Copy this code, but modify the *if* statement condition and *print* statement to print out each sentence if it contains a date. Note that *break* is used to break out of the inner loop (otherwise you would print a sentence multiple times if it contained  multiple dates).\n",
    "\n",
    "```python\n",
    "# for each setence in the document\n",
    "for s in doc.sents :\n",
    "    # for each entity in the sentence\n",
    "    for ent in s.ents :        \n",
    "        # if the entity is a date\n",
    "        if the entity is a date :\n",
    "            # print out the sentence\n",
    "            print out the sentence\n",
    "            break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
