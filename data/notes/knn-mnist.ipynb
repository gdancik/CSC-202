{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# K-Nearest Neighbor classification on *MNIST* handwritten image dataset\n",
    "\n",
    "In this notebook we will use *kNN* to classify the *MNIST* (Modified National Institute of Standards and Technology) database of handwritten digits (http://yann.lecun.com/exdb/mnist/ ). The full dataset consists of 60,000 training samples and 10,000 test samples of images that were 28 x 28 pixels wide; a simplified version was produced containing 5,620 images that are 8 x 8 pixels wide (http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits ). The *scikit-learn* module contains a subset of these images. \n",
    "\n",
    "## Loading and understanding the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# This describes the processed dataset containing 5,620 images; our dataset is smaller as will be seen below\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Extract the features and the target values (class labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*X* is two-dimensional and has 1797 rows and 64 columns. The 64 columns represents a 'flattened' version of the 8x8 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*y* has 1797 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "The image representation can be accessed by looking at *digits.images*, a **three-dimensional** array of 1797 images, where each image is an 8x8 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's look at the first image, which is an 8x8 array of pixel intensities. Slicing rules for arrays apply, except now we have 3 dimensions. Furthermore, to access a single image at index *i*, note that\n",
    "\n",
    "```python\n",
    "X[i]\n",
    "```\n",
    "is the same as\n",
    "\n",
    "```python\n",
    "X[i,:,:]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's *view* the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digits.images[0], cmap = plt.cm.gray_r)\n",
    "plt.axis('off')\n",
    "plt.title('Number: ' + str(y[0]))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's generate images for the first 30 numbers. We use the method *subplots* to specify we want to plot 3 rows of images with 10 images in each row; each image will be 15x6. This method returns a tuple containing two elements: the *figure*, and an array of *axes* objects (for each subfigure). The *ravel* method is used to *flatten* the axes array (more on this below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# set up the plot\n",
    "figure, axes = plt.subplots(3,10, figsize = (15,6))\n",
    "\n",
    "for ax,image,number in zip(axes.ravel(), digits.images, y) :\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image, cmap = plt.cm.gray_r)\n",
    "    ax.set_title('Number: ' + str(number))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Flattening numpy arrays\n",
    "\n",
    "Sometimes data in multidimensional arrays need to be *flattened* to a one-dimensional array. In the code above, axes is a two-dimensional array with 3 rows and 10 columns. In order to iterate over each figure, we need to flatten the array. \n",
    "\n",
    "In classification, the feature data for a *single* sample must be stored in a one-dimensional array (even if this is not the actual structure), and the feature data for *all* samples must be a two-dimensional array. But what if the feature data for a sample is an 8x8 image? The solution is to *flatten* the data. The *ravel* method will flatten data by reading the array row by row. The feature data (stored in *X*) contains the flattened version of each array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "image = digits.images[0]\n",
    "print('original image data =')\n",
    "print(image)\n",
    "print()\n",
    "\n",
    "image_flattened = image.ravel()\n",
    "print('flattened image = ')\n",
    "print(image_flattened)\n",
    "print()\n",
    "\n",
    "print('feature data = ')\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## K-nearest neighbor classification on *MNIST* using training and testing datasets\n",
    "\n",
    "\n",
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Make predictions in the *test* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results by generating a *classification report*  which calculates various performance measures\n",
    "\n",
    "Our *kNN* classifier correctly identifies most digits 99% of the time, on average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Evaluate the results by looking at the *confusion matrix*\n",
    "\n",
    "A *confusion matrix* is a matrix that shows how the observations in each row (each class) were classified (corresponding to each column). As the name implies, confusion matrices are useful for identifying areas where the classifier may be \"confused\" (i.e., where it consistently misclassifies a particular category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can visualize the heatmap using the seaborn *heatmap* function. \n",
    "\n",
    "We do not create a data frame because we did not need to assign row and column names (since the default values, 0 - 9, correspond to the class values.\n",
    "\n",
    "Are there are numbers which tend to be mis-classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "s = sns.heatmap(confusion, annot = True, cmap = 'nipy_spectral_r')\n",
    "s.set_title('Confusion matrix for MNIST dataset')\n",
    "plt.ylabel('True Value')\n",
    "plt.xlabel('Predicted Value')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting specific performance measures\n",
    "\n",
    "We can get the accuracy (number correct / number of observations) by using either the *knn.score* method or the *metrics.accuracy.score* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# calculate the overall accuracy using knn.score\n",
    "acc = knn.score(X_test, y_test)\n",
    "print(f'accuracy from knn.score = {acc:.4}') \n",
    "\n",
    "# calculate the overall accuracy using metrics.accuracy_score\n",
    "from sklearn import metrics\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy from metrics.accuracy_score = {acc:.4}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "However, overal accuracy may not a good measure. Why?\n",
    "\n",
    "Balanced accuracy is a type of accuracy that assumes the number of samples for each target is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# calculate the balanced accuracy using metrics.accuracy_score\n",
    "acc = metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy = {acc:.4}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
