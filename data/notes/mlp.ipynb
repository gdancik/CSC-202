{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Multilayer perceptron classification using *scikit-learn*\n",
    "\n",
    "In this notebook we will use a multilayer perceptron to classify a subset of the *MNIST* (Modified National Institute of Standards and Technology) database of handwritten digits (http://yann.lecun.com/exdb/mnist/ ). A multilayer perceptron is a feedforward artificial neural network.\n",
    "\n",
    "\n",
    "The basic steps for model fitting and testing are the same as for *kNN*, except for neural networks you should always scale your data.\n",
    "\n",
    "1. Scale the data so each feature is on the same scale\n",
    "2. Create the estimator or model, using *MLPClassifier*\n",
    "3. Train the model using model.train()\n",
    "4. Make predictions using model.predict()\n",
    "\n",
    "\n",
    "\n",
    "## Loading and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "To demonstrate how the multilayer perceptron works, we will look only at the digits 0, 1, and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "keep = np.logical_or(digits.target <= 1, digits.target == 7) \n",
    "\n",
    "digits.data = digits.data[keep,]\n",
    "digits.target = digits.target[keep]\n",
    "digits.images = digits.images[keep,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Stores the features in *X* and the target values in _y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The feature matrix _X_ is a 2D array with dimensions 539 x 64; each row contains the 64 features for a sample, which is the 'flattened' version of the 8x8 image; *y* contains the 539 target values (for the values 0, 1, and 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('Shape of X is: ', X.shape)\n",
    "print('Shape of y is: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's visualize the first 30 numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set up the plot\n",
    "figure, axes = plt.subplots(3,10, figsize = (15,6))\n",
    "\n",
    "for ax,image,number in zip(axes.ravel(), digits.images, y) :\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image, cmap = plt.cm.gray_r)\n",
    "    ax.set_title('Number: ' + str(number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Split the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=17, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Scale the data\n",
    "\n",
    "Neural networks perform better if all features are on the same scale. We use the *StandardScaler* which scales each feature to have a mean (average) of 0 and a variance of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# then user the scaler to scale the training and testing data \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Each feature now has mean 0 and variance 1 (unless all training values are the same, in which case the variance will be 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# look at first 5 column means and variances:\n",
    "import pandas as pd\n",
    "Xmeans = X_train.mean(axis = 0)[:5]\n",
    "Xvars = X_train.var(axis = 0)[:5]\n",
    "df = pd.DataFrame( {'mean': Xmeans, 'var': Xvars} )\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Fit the model\n",
    "\n",
    "We can train a neural network using the Multilayer perceptron classifier (*MLPClassifier*) from *scikit-learn*.\n",
    "\n",
    "For this classifier we specify the following:\n",
    "\n",
    "- hidden_layer_sizes: a single value for the size of the hidden a layer, or a list of values for the sizes of multiple hidden layers\n",
    "- max_iter: the maximum number of epochs (the number of times each data point is used)\n",
    "- verbose: set to True to print progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=4, max_iter=1000, verbose = True, random_state=211)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can plot the loss function to see how well our model is learning. If the loss curve should stabilize at a lower value; if not, then adjustments should be made (such as having more epochs, increasing the amount of training data, or changing some of the training model parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('The loss curve for our mlp classifier')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Make predictions in the *test* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Evaluate the results by generating a *classification report*  which calculates various performance measures\n",
    "\n",
    "Our *multilayer perceptron* classifier correctly identifies 0,1, and 7 (nearly) 100% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Evaluate the results by looking at the *confusion matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "confusion = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "df = pd.DataFrame(confusion, columns= [0,1,7], index = [0,1,7])\n",
    "s = sns.heatmap(df, annot = True, cmap = 'nipy_spectral_r', )\n",
    "s.set_title('Confusion matrix for MNIST dataset')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Let's understand the structure of our neural network\n",
    "\n",
    "We can get the weights and biases from \n",
    "- *mlp.coefs_*:  a list containing the weight matrices, containing the weight of each input for each node in the layer\n",
    "- *mlp.intercepts_*: a list of the biases for each layer (every node in a layer has a bias term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "for i,c in enumerate(mlp.coefs_) :\n",
    "    print('weight matrix for layer #', i + 1, ': ', c.shape, sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Our neural network has the following structure:\n",
    "- an input layer consisting of 64 nodes (the 64 features, representing the 8x8 grid of pixels for a sample)\n",
    "- a hidden layer consisting of 4 nodes\n",
    "- an output layer consisting of 3 nodes (corresponding to the probabilities that the sample is a 0,1, or 7, respectively)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The *mlp.predict* method can be used to make a prediction, and get the predicted value. However this prediction is based on comparing the predicted probabilities for each class, and selecting the class with the maximum probability. This is illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "preds = mlp.predict(X_test)\n",
    "pred_probs = mlp.predict_proba(X_test).round(2)\n",
    "\n",
    "l = [ [num, *matrix] for num, matrix in zip(preds[:3], pred_probs[:3])]\n",
    "pd.DataFrame(l, columns = ['predicted value', 'prob(0)', 'prob(1)', 'prob(7)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Visualizing the weights of the neural network\n",
    "\n",
    "In order to understand how the neural network works, let's visualize the weight matrix for each of the 4 neurons in the hidden layer. Darker values indicate larger weights, and inputs with higher weights will have a larger effect on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4)\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(8, 8), cmap=plt.cm.gray_r)#, vmin=.5 * vmin,vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Each hidden node captures one or more features (local structures) that help classify the number.\n",
    "The code below looks at the weights applied to inputs from the hidden layer to the *output* layer. This shows how activation of the hidden nodes influences the prediction. For example, if the first hidden node is activated, what number (0,1, or 7) would be predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(mlp.coefs_[1].round(2), index = ['hidden node 1', 'hidden node 2', 'hidden node 3', 'hidden node 4'],\n",
    "            columns = ['prob(0)', 'prob(1)', 'prob(7)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
