{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Natural language processing using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*Natural language processing (NLP)* involves the analysis and extraction of meaningful information from natural language data, such as speech or text. This notebook demonstrates several *NLP* methods using the Python module *TextBlob* (https://textblob.readthedocs.io/en/dev/).\n",
    "\n",
    "We will look at the following analyses:\n",
    "Tokenization, Stemming, Noun phrase extraction, sentiment analysis, word count analysis, and language translation powered by Google Translate.\n",
    "\n",
    "To use TextBlob, you must import it (see below), and then create a *TextBlob* object. By convention the *TextBlob* object is stored in a variable named *blob*, as in the example below:\n",
    "\n",
    "```python\n",
    "blob = TextBlob('text to analyze')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Triple quotes are used to denote a multi-line string\n",
    "# Quote from Jude Christodal\n",
    "stage = \"\"\"All the world's a stage, and every word a note.\n",
    "And every day is filled with songs you never knew you wrote.\"\"\"\n",
    "\n",
    "# printing stage will output across multiple lines\n",
    "print(stage)\n",
    "\n",
    "# viewing the string we can see the newline ('\\n') characters\n",
    "stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# create a TextBlob object\n",
    "from textblob import TextBlob\n",
    "blob = TextBlob(stage)\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "*Tokenization* is the process of splitting text into meaningful pieces (sequences of characters), such as words or sentences. In general, these  pieces are referred to as tokens. TextBlob will automatically parse text into words and sentences. \n",
    "\n",
    "*TextBlob* objects contain many properties (or fields) that can be accessed using the dot ('.') operator. \n",
    "\n",
    "In particular for tokenization, for a *TextBlob* object named *blob*,\n",
    "\n",
    "- *blob.words* returns a list of *words*, stored in a WordList object that behaves like an ordinary *list*\n",
    "- *blob.sentences* returns a list of sentences, stored as a list of Sentence objects\n",
    "\n",
    "\n",
    "**Note**: The first time running this, you will be prompted to install a tokenizer. Run the following code and press enter:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# get a list of words\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "How many words are there? What is the first word?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# get a list of sentences\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Note**: Each sentence has all the properties of a *TextBlob* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# get first sentence\n",
    "sentence1 = blob.sentences[0]\n",
    "\n",
    "# Since sentence1 is like a TextBlob, we can get its words using the following\n",
    "sentence1.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of speech tagging\n",
    "\n",
    "*TextBlob* automatically carries out part-of-speech tagging, as shown below. The *tags* property includes a list of tuples in the form (word, part of speech). Common tags include *NN* for noun (singular or mass), *NNS* for noun (plural), and *VBN*, *VBZ*, and *VB* which are different types of verbs. For a list of tags, see https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "**Note**: the first time running this code you will be asked to install a tagger. Run the following code and press enter.\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "Print out all of the nouns (which have tags of 'NN', or 'NNS', 'NNP', or 'NNPS'; no other part of speech contains an 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Noun phrase extraction\n",
    "\n",
    "*Noun phrase extraction* involves the identification of *noun phrases*, which are phrases that include nouns (possibly following one or more adjectives)\n",
    "\n",
    "For a *TextBlob* object named *blob*, a list of noun phrases are returned using *blob.noun_phrases*.\n",
    "\n",
    "**Note**: the first time running this code, you will be asked to install a corpus used to identify noun phrases. Text corpora are described at https://www.nltk.org/book/ch02.html. Run the following code:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob('Amy has a new red car')\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "A *sentiment analysis* measures the emotional content of text. We will use sentiment analysis to identify text as *positive* or *negative*, though other emotions can also be detected.\n",
    "\n",
    "For a *TextBlob* object named *blob*, its sentiment can be found by using *blob.sentiment*, which will give you a Sentiment object (a named tuple) that contains the following:\n",
    "\n",
    "- polarity: a score between -1 (negative sentiment) and +1 (positive sentiment)\n",
    "- subjectivity: a score between 0 (objective) and +1 (subjective)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob('I love this class')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob('This class sucks!')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# the sentiment of a text blob will represent an average sentiment over multiple sentiments\n",
    "blob = TextBlob('This class is great. This class is awesome. This class sucks. This class sucks!!! This class is okay.')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# but we can find the polarity of each sentence\n",
    "for s in blob.sentences:\n",
    "    print('\"', s, '\" has a polarity of ', s.sentiment.polarity, sep = '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Stemming \n",
    "\n",
    "*Stemming* is a normalization method that takes a word and converts it into a *base* form by removing word endings (suffixes) or prefixes.\n",
    "\n",
    "For a *TextBlob* word object, you can get the *stem* by calling *word.stem()*.\n",
    "\n",
    "Lemmatization is a related technique that takes the word's part of speech into account and returns a dictionary form of the word.\n",
    "\n",
    "Stemming and lemmatization are useful for counting words, since different forms of the same word (like 'runs' and 'run' should probably be counted as one word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob('run runs running ran')\n",
    "\n",
    "# get word stems\n",
    "for w in blob.words :\n",
    "    print(w, ': ', w.stem(), sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Word counts\n",
    "\n",
    "Word counts are automatically calculated when a *TextBlob* object is created. The word counts of a *TextBlob* named *blob* are stored in *blob.word_counts*, which is a default dictionary (a dictionary where keys that do not exist have a default value, which in this case is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Song lyrics by House of Pain\n",
    "jump = 'So get out your seat and jump around! Jump around! Jump around! Jump up, jump up and get down!'\n",
    "blob = TextBlob(jump)\n",
    "blob.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How many times does 'jump' appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob.word_counts['jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Because word_counts is a default dictionary, looking up a word not in the dictionary will return 0, and also add the word to the dictionary! Note: we could remove a key from a dictionary *d* by using *d.pop(key)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "blob.word_counts['cheese']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can iterate through the keys of a dictionary using a for loop (*for keys in dict*). We also can iterate through key,value pairs of a dictionary by using *dictionary.items()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "for word, count in blob.word_counts.items() :\n",
    "    print(word, ': ', count, sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Stopwords\n",
    "\n",
    "Stopwords are common words (like 'a' and 'the') that should be ignored when analyzing text.\n",
    "\n",
    "We can get a list of stopwords from the *nltk.corpus*, using the function *stopwords.words()*. We convert this list to a *set*, which is a collection of unordered items (i.e., it is *not* a sequence). The advantage of a set is that it has a constant lookup time, meaning that it is faster to test whether an item is in a set than testing when an item is in a list.\n",
    "\n",
    "**Note**: We will first need to install the set of stopwords by running the following code:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# create a set of stopwords\n",
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Removing stop words\n",
    "\n",
    "List comprehension can be used to create a list of (word, frequency) tuples with stop words removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# create a list of (word, frequency) tuples but with stop words removed\n",
    "words = [ (w, f) for w,f in blob.word_counts.items() if w not in sw]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Sorting by frequency\n",
    "\n",
    "The following code will return a sorted list, where the sorting is based on reading list elements from left to right.\n",
    "```python\n",
    "sorted(listName)\n",
    "```\n",
    "\n",
    "If the lists contains tuples, then sorting will be based on the first element of each tuple. But sometimes we want to sort based on another element. This is accomplished by specifying the *key* argument to the *sorted* function. An *itemgetter* can be used here to specify the *index* to use for sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# sort the list\n",
    "from operator import itemgetter\n",
    "\n",
    "# sort the word list by frequency (stored in index 1 of each tuple) in reverse order (highest to lowest)\n",
    "words = sorted(words, key = itemgetter(1), reverse=True)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Generating a bar graph of word frequencies\n",
    "\n",
    "A *bar graph* visualizes word frequencies by using a bar for each word; the height of the bar corresponds to the frequency of the word. \n",
    "\n",
    "In order to create a bar graph, we first create a data frame (a table) of word frequencies. The *pandas* module is used to create the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a data frame from a list of tuples (each element will be a column)\n",
    "df = pd.DataFrame(words, columns = ['word', 'frequency'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can then create a bar graph directly from the data frame, using pandas *plot.bar* function. Note that a *None* is included at the end the cell to prevent the cell from displaying the value returned by the *ax.set_title* statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# generate a bar graph, where 'x' and 'y' are the data frame columns to use\n",
    "ax = df.plot.bar(x = 'word', y = 'frequency', legend = False, color = 'lightblue')\n",
    "\n",
    "# add y-axis labels and a title\n",
    "ax.set_ylabel('frequency')\n",
    "ax.set_title('Word Counts')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Because we looked up 'cheese' previously, this was added to the dictionary. How can we update the words list of tuples to remove (word, frequency) pairs where the frequency was 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can generate a horizontal bar graph using the 'plot.barh' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "ax = df.plot.barh(x = 'word', y = 'frequency', legend = False)\n",
    "ax.set_xlabel('frequency')\n",
    "ax.set_title('Word Counts')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Word clouds\n",
    "\n",
    "A *word cloud* is a visualization of words where the size of each word is proportional to its frequency. Word clouds can be generated directly from text or from a dictionary containing words and their corresponding frequencies.\n",
    "\n",
    "The default WordCloud has the following arguments:\n",
    "\n",
    "```python\n",
    "WordCloud(background_color = 'black', stopwords = None, colormap = 'viridis', ...)\n",
    "```\n",
    "\n",
    "The *stopwords* argument can be a set of strings of stop words to remove; the default value of *None* will use a built-in stopwords list.\n",
    "\n",
    "For additional colormaps see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# generate a word cloud from text (stop words will be removed)\n",
    "wordcloud = WordCloud().generate(jump)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# generate a word cloud from a dictionary of frequencies\n",
    "wordcloud = WordCloud(colormap = 'prism').generate_from_frequencies(blob.word_counts)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
